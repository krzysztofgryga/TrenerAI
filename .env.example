# =============================================================================
# TrenerAI Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env

# =============================================================================
# SECURITY (WYMAGANE W PRODUKCJI!)
# =============================================================================

# JWT Secret Key - wygeneruj unikalny klucz!
# python -c "import secrets; print(secrets.token_hex(32))"
JWT_SECRET_KEY=your-super-secret-key-change-in-production

# Czas życia tokenu w minutach (default: 1440 = 24h)
JWT_EXPIRE_MINUTES=1440

# =============================================================================
# DATABASE
# =============================================================================

# PostgreSQL
DATABASE_URL=postgresql://trainer:trainer123@localhost:5432/trenerai

# Dla Docker:
# DATABASE_URL=postgresql://trainer:trainer123@postgres:5432/trenerai

# =============================================================================
# VECTOR DATABASE (QDRANT)
# =============================================================================

QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=gym_exercises

# Dla Docker:
# QDRANT_HOST=qdrant

# =============================================================================
# LLM PROVIDER
# =============================================================================

# Opcje: "openai" lub "ollama"
LLM_PROVIDER=ollama

# Nazwa modelu (zależy od providera)
# OpenAI: gpt-4o, gpt-4o-mini, gpt-3.5-turbo
# Ollama: llama3.2, mistral, qwen2.5:7b
LLM_MODEL=qwen2.5:7b
LLM_TEMPERATURE=0.2

# =============================================================================
# OPENAI (tylko jeśli LLM_PROVIDER=openai)
# =============================================================================

OPENAI_API_KEY=your-openai-api-key-here

# =============================================================================
# OLLAMA (tylko jeśli LLM_PROVIDER=ollama)
# =============================================================================

OLLAMA_BASE_URL=http://localhost:11434

# Dla Docker:
# OLLAMA_BASE_URL=http://ollama:11434

# =============================================================================
# OPTIONAL: RATE LIMITING
# =============================================================================

# Requests per minute per IP
RATE_LIMIT_PER_MINUTE=60

# =============================================================================
# OPTIONAL: LOGGING
# =============================================================================

# Poziom logowania: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO
